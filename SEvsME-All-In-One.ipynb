{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8bd3d5d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:28.419082Z",
     "iopub.status.busy": "2022-10-02T15:18:28.418184Z",
     "iopub.status.idle": "2022-10-02T15:18:47.811499Z",
     "shell.execute_reply": "2022-10-02T15:18:47.810127Z",
     "shell.execute_reply.started": "2022-10-02T15:18:28.419043Z"
    },
    "papermill": {
     "duration": 2.005166,
     "end_time": "2022-06-28T15:08:22.288940",
     "exception": false,
     "start_time": "2022-06-28T15:08:20.283774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "\n",
    "from pathlib import Path\n",
    "from six.moves import urllib\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ofa.utils import AverageMeter, accuracy\n",
    "from torchprofile.profile import profile_macs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4683989f",
   "metadata": {},
   "source": [
    "# DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a18d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:47.819450Z",
     "iopub.status.busy": "2022-10-02T15:18:47.817140Z",
     "iopub.status.idle": "2022-10-02T15:18:47.829265Z",
     "shell.execute_reply": "2022-10-02T15:18:47.828423Z",
     "shell.execute_reply.started": "2022-10-02T15:18:47.819406Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loaders(train_dataset, validation_dataset, test_dataset, batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, num_workers=8, shuffle=True, pin_memory=True)\n",
    "    validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size, num_workers=8, shuffle=False, pin_memory=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size, num_workers=8, shuffle=False, pin_memory=True)\n",
    "    return train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc50466",
   "metadata": {},
   "source": [
    "## dataset generators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb1ebd3",
   "metadata": {},
   "source": [
    "### cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356d912e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:47.837304Z",
     "iopub.status.busy": "2022-10-02T15:18:47.834347Z",
     "iopub.status.idle": "2022-10-02T15:18:47.846888Z",
     "shell.execute_reply": "2022-10-02T15:18:47.845982Z",
     "shell.execute_reply.started": "2022-10-02T15:18:47.837263Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cifar10(root=\"./datasets\", img_size=32):\n",
    "    \n",
    "    n_classes = 10\n",
    "    img_channels = 3\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size=(img_size,img_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768))\n",
    "    ])\n",
    "    \n",
    "    # create train and test set\n",
    "    train_val_dataset = torchvision.datasets.CIFAR10(root=root, train=True,download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root=root, train=False,download=True, transform=transform) \n",
    "\n",
    "    #generate the validtion set\n",
    "    torch.manual_seed(420)\n",
    "    val_size = 5000 #10%\n",
    "    train_size = len(train_val_dataset) - val_size\n",
    "    train_dataset, validation_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "    classes_weights=None\n",
    "\n",
    "    return  n_classes, img_channels, train_dataset, validation_dataset, test_dataset, classes_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843159c5",
   "metadata": {},
   "source": [
    "### cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88c125fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:47.850444Z",
     "iopub.status.busy": "2022-10-02T15:18:47.850036Z",
     "iopub.status.idle": "2022-10-02T15:18:47.861113Z",
     "shell.execute_reply": "2022-10-02T15:18:47.860165Z",
     "shell.execute_reply.started": "2022-10-02T15:18:47.850414Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cifar100(root=\"./datasets\", img_size=32):\n",
    "\n",
    "    n_classes = 100\n",
    "    img_channels = 3\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size=(img_size,img_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768))\n",
    "    ])\n",
    "    \n",
    "    # create train and test set\n",
    "    train_val_dataset = torchvision.datasets.CIFAR100(root=root, train=True,download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR100(root=root, train=False,download=True, transform=transform) \n",
    "\n",
    "    #generate the validtion set\n",
    "    torch.manual_seed(420)\n",
    "    val_size = 5000 #10%\n",
    "    train_size = len(train_val_dataset) - val_size\n",
    "    train_dataset, validation_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "    classes_weights=None\n",
    "\n",
    "    return  n_classes, img_channels, train_dataset, validation_dataset, test_dataset, classes_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9dfa5b",
   "metadata": {},
   "source": [
    "### tiny imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53df0a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:47.863194Z",
     "iopub.status.busy": "2022-10-02T15:18:47.862795Z",
     "iopub.status.idle": "2022-10-02T15:18:47.872242Z",
     "shell.execute_reply": "2022-10-02T15:18:47.871328Z",
     "shell.execute_reply.started": "2022-10-02T15:18:47.863144Z"
    }
   },
   "outputs": [],
   "source": [
    "def rename_subfolders(root_dir, old_new_names_dict):\n",
    "    old_names = []\n",
    "    for it in os.scandir(root_dir):\n",
    "        if it.is_dir():\n",
    "            old_name = os.path.split(it.path)[-1]\n",
    "            old_names.append(old_name)\n",
    "\n",
    "    for old_name in old_names:\n",
    "        old_path = os.path.join(root_dir, old_name)\n",
    "        new_name = old_new_names_dict[old_name]\n",
    "        new_path = os.path.join(root_dir, new_name)\n",
    "        os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25e2760",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:47.874533Z",
     "iopub.status.busy": "2022-10-02T15:18:47.873968Z",
     "iopub.status.idle": "2022-10-02T15:18:47.891878Z",
     "shell.execute_reply": "2022-10-02T15:18:47.890882Z",
     "shell.execute_reply.started": "2022-10-02T15:18:47.874498Z"
    }
   },
   "outputs": [],
   "source": [
    "class TinyImagenetDownloader:\n",
    "    \n",
    "    def __init__(self,dataset_path):\n",
    "        \n",
    "        self.save_path=dataset_path\n",
    "        \n",
    "        self.train_path=os.path.join(dataset_path,\"train\")\n",
    "        \n",
    "        self.valid_path=os.path.join(dataset_path,\"val\")\n",
    "        self.valid_path=os.path.join(self.valid_path,\"images\")\n",
    "        \n",
    "        self.data_url=\"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "        \n",
    "        self.download_dataset()\n",
    "    \n",
    "    '''\n",
    "         This method is responsible for separating validation images into separate sub folders\n",
    "         modified from https://github.com/DennisHanyuanXu/Tiny-ImageNet/blob/f08f6e69375a8142ecdff76afd9457620f399f48/src/data_prep.py\n",
    "         '''\n",
    "    def create_val_img_folder(self):\n",
    "\n",
    "        dataset_dir = self.save_path\n",
    "        val_dir = os.path.join(dataset_dir, 'val')\n",
    "        img_dir = os.path.join(val_dir, 'images')\n",
    "\n",
    "        fp = open(os.path.join(val_dir, 'val_annotations.txt'), 'r')\n",
    "        data = fp.readlines()\n",
    "        val_img_dict = {}\n",
    "        for line in data:\n",
    "            words = line.split('\\t')\n",
    "            val_img_dict[words[0]] = words[1]\n",
    "        fp.close()\n",
    "\n",
    "        # Create folder if not present and move images into proper folders\n",
    "        for img, folder in val_img_dict.items():\n",
    "            newpath = (os.path.join(img_dir, folder))\n",
    "            if not os.path.exists(newpath):\n",
    "                os.makedirs(newpath)\n",
    "            if os.path.exists(os.path.join(img_dir, img)):\n",
    "                os.rename(os.path.join(img_dir, img), os.path.join(newpath, img))\n",
    "\n",
    "    '''\n",
    "    This method is responsible for converting the class identifier to the class name\n",
    "    modified from https://github.com/DennisHanyuanXu/Tiny-ImageNet/blob/f08f6e69375a8142ecdff76afd9457620f399f48/src/data_prep.py\n",
    "    '''\n",
    "    def get_class_name(self):\n",
    "        class_to_name = dict()\n",
    "        fp = open(os.path.join(self.save_path, 'words.txt'), 'r')\n",
    "        data = fp.readlines()\n",
    "        for line in data:\n",
    "            words = line.strip('\\n').split('\\t')\n",
    "            class_to_name[words[0]] = words[1].split(',')[0]\n",
    "        fp.close()\n",
    "        return class_to_name\n",
    "\n",
    "    def rename_folders(self):\n",
    "        class_to_name = self.get_class_name()\n",
    "        rename_subfolders(self.train_path, class_to_name)\n",
    "        rename_subfolders(self.valid_path, class_to_name)\n",
    "\n",
    "    def download_dataset(self):\n",
    "\n",
    "        # check if the unzipped folder already exists ...\n",
    "        if not os.path.exists(self.save_path):\n",
    "\n",
    "            # if not create parent directory\n",
    "            parent_dir = Path(self.save_path).parent\n",
    "            os.makedirs(parent_dir)\n",
    "\n",
    "            # download there the zip file\n",
    "            print('Downloading %s' % self.data_url)\n",
    "            data_zip = urllib.request.urlopen(self.data_url)\n",
    "            # download .zip file\n",
    "            zip_path = os.path.join(parent_dir, \"tiny-imagenet-200.zip\")\n",
    "            with open(zip_path, 'wb') as f:\n",
    "                f.write(data_zip.read())\n",
    "            print(\"Download complete\")\n",
    "\n",
    "            # unzip it\n",
    "            print(\"Unzipping the Dataset, please wait\")\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(parent_dir)\n",
    "            print(\"Unzip complete\")\n",
    "\n",
    "            # move validation images into folders\n",
    "            self.create_val_img_folder()\n",
    "\n",
    "            # rename the validation folders\n",
    "            self.rename_folders()\n",
    "\n",
    "            # delete the zip file\n",
    "            # os.remove(zip_path)\n",
    "        else:\n",
    "            print(\"already there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7482acd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:47.893867Z",
     "iopub.status.busy": "2022-10-02T15:18:47.893365Z",
     "iopub.status.idle": "2022-10-02T15:18:47.906132Z",
     "shell.execute_reply": "2022-10-02T15:18:47.905209Z",
     "shell.execute_reply.started": "2022-10-02T15:18:47.893831Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tiny_imagenet(root=\"./datasets\", img_size=64):\n",
    "\n",
    "    n_classes = 200\n",
    "    img_channels = 3\n",
    "\n",
    "    dataset_path = os.path.join(root,\"tiny-imagenet\",\"tiny-imagenet-200\")\n",
    "    TinyImagenetDownloader(dataset_path)\n",
    "\n",
    "    # define transformations\n",
    "    train_transforms=[\n",
    "        transforms.Resize(size=(img_size,img_size),interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2770, 0.2691, 0.2821])\n",
    "    ]\n",
    "    train_transforms=transforms.Compose(train_transforms)\n",
    "\n",
    "    valid_transforms=[\n",
    "        transforms.Resize(size=(img_size,img_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2770, 0.2691, 0.2821])\n",
    "    ]\n",
    "    valid_transforms=transforms.Compose(valid_transforms)\n",
    "\n",
    "    train_path=os.path.join(dataset_path,\"train\")\n",
    "    test_path=os.path.join(dataset_path,\"val\",\"images\")\n",
    "\n",
    "    # generate train and test sets\n",
    "    train_val_dataset= torchvision.datasets.ImageFolder(train_path,train_transforms)\n",
    "    test_dataset= torchvision.datasets.ImageFolder(test_path,valid_transforms)\n",
    "\n",
    "    #generate the validation set\n",
    "    torch.manual_seed(420)\n",
    "    val_size = 10000 #10%\n",
    "    train_size = len(train_val_dataset) - val_size\n",
    "    train_dataset, validation_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "    classes_weights=None\n",
    "\n",
    "    return  n_classes, img_channels, train_dataset, validation_dataset, test_dataset, classes_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6aa86",
   "metadata": {},
   "source": [
    "### fashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51acd6c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:47.908926Z",
     "iopub.status.busy": "2022-10-02T15:18:47.907670Z",
     "iopub.status.idle": "2022-10-02T15:18:47.918853Z",
     "shell.execute_reply": "2022-10-02T15:18:47.917927Z",
     "shell.execute_reply.started": "2022-10-02T15:18:47.908897Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_fashionMNIST(root=\"./datasets\", img_size=28):\n",
    "\n",
    "    n_classes = 10\n",
    "    img_channels = 1\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size=(img_size,img_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0.5, 0.5)\n",
    "    ])\n",
    "\n",
    "    # create train and test set\n",
    "    train_val_dataset = torchvision.datasets.FashionMNIST(root=root, train=True,download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.FashionMNIST(root=root, train=False,download=True, transform=transform)\n",
    "\n",
    "    #generate the validation set\n",
    "    torch.manual_seed(420)\n",
    "    val_size = 9000 #15%\n",
    "    train_size = len(train_val_dataset) - val_size\n",
    "    train_dataset, validation_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "    classes_weights=None\n",
    "\n",
    "    return  n_classes, img_channels, train_dataset, validation_dataset, test_dataset, classes_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525e593",
   "metadata": {},
   "source": [
    "### eurosat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11882519",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:47.922652Z",
     "iopub.status.busy": "2022-10-02T15:18:47.922149Z",
     "iopub.status.idle": "2022-10-02T15:18:47.932830Z",
     "shell.execute_reply": "2022-10-02T15:18:47.931821Z",
     "shell.execute_reply.started": "2022-10-02T15:18:47.922627Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_eurosat(root=\"./datasets\", img_size=64):\n",
    "\n",
    "    n_classes = 10\n",
    "    img_channels = 3\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size=(img_size,img_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25))\n",
    "    ])\n",
    "\n",
    "    # create the dataset\n",
    "    dataset = torchvision.datasets.EuroSAT(root=root, download=True, transform=transform)\n",
    "\n",
    "    # partition the dataset in train, validation and test\n",
    "    torch.manual_seed(420)\n",
    "    val_size = 4000 #15%\n",
    "    test_size = 5500 #20%\n",
    "    train_size = len(dataset) - val_size - test_size\n",
    "    train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    classes_weights = torch.Tensor([0.9, 0.9, 0.9, 1.08, 1.08, 1.35, 1.08, 0.9, 1.08, 0.9])\n",
    "    #classes_weights = None\n",
    "\n",
    "    return  n_classes, img_channels, train_dataset, validation_dataset, test_dataset, classes_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ca134",
   "metadata": {},
   "source": [
    "### GTSRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f0099f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:47.937626Z",
     "iopub.status.busy": "2022-10-02T15:18:47.937280Z",
     "iopub.status.idle": "2022-10-02T15:18:47.946469Z",
     "shell.execute_reply": "2022-10-02T15:18:47.945428Z",
     "shell.execute_reply.started": "2022-10-02T15:18:47.937601Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_gtsrb(root=\"./datasets\", img_size=(1360,1024)):\n",
    "\n",
    "    n_classes = 43\n",
    "    img_channels = 3\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size=(img_size,img_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629))\n",
    "\n",
    "    ])\n",
    "\n",
    "    # create the dataset\n",
    "    train_val_dataset = torchvision.datasets.GTSRB(root=root, split=\"train\", download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.GTSRB(root=root, split=\"test\", download=True, transform=transform)\n",
    "\n",
    "    #generate the validation set\n",
    "    torch.manual_seed(420)\n",
    "    val_size = 6000 #15%\n",
    "    train_size = len(train_val_dataset) - val_size\n",
    "    train_dataset, validation_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "    classes_weights = torch.Tensor([\n",
    "        4.130232558139535,\n",
    "        0.4130232558139535,\n",
    "        0.4130232558139535,\n",
    "        0.6453488372093024,\n",
    "        0.4693446088794926,\n",
    "        0.49169435215946844,\n",
    "        2.0651162790697675,\n",
    "        0.6453488372093024,\n",
    "        0.6453488372093024,\n",
    "        0.6257928118393234,\n",
    "        0.45891472868217054,\n",
    "        0.6883720930232559,\n",
    "        0.4393864423552697,\n",
    "        0.43023255813953487,\n",
    "        1.1472868217054264,\n",
    "        1.4750830564784052,\n",
    "        2.0651162790697675,\n",
    "        0.826046511627907,\n",
    "        0.7648578811369509,\n",
    "        4.130232558139535,\n",
    "        2.5813953488372094,\n",
    "        2.5813953488372094,\n",
    "        2.294573643410853,\n",
    "        1.7209302325581395,\n",
    "        3.441860465116279,\n",
    "        0.6073871409028728,\n",
    "        1.4750830564784052,\n",
    "        3.441860465116279,\n",
    "        1.7209302325581395,\n",
    "        3.441860465116279,\n",
    "        2.0651162790697675,\n",
    "        1.1472868217054264,\n",
    "        3.441860465116279,\n",
    "        1.2906976744186047,\n",
    "        2.0651162790697675,\n",
    "        0.7648578811369509,\n",
    "        2.294573643410853,\n",
    "        4.130232558139535,\n",
    "        0.448938321536906,\n",
    "        2.9501661129568104,\n",
    "        2.5813953488372094,\n",
    "        3.441860465116279,\n",
    "        3.441860465116279\n",
    "    ])\n",
    "    #classes_weights = None\n",
    "\n",
    "    return  n_classes, img_channels, train_dataset, validation_dataset, test_dataset, classes_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf5d76e",
   "metadata": {},
   "source": [
    "## show samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef09d787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:47.948513Z",
     "iopub.status.busy": "2022-10-02T15:18:47.948103Z",
     "iopub.status.idle": "2022-10-02T15:18:47.959059Z",
     "shell.execute_reply": "2022-10-02T15:18:47.958164Z",
     "shell.execute_reply.started": "2022-10-02T15:18:47.948477Z"
    },
    "papermill": {
     "duration": 3.426921,
     "end_time": "2022-06-28T15:08:46.899574",
     "exception": false,
     "start_time": "2022-06-28T15:08:43.472653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show a batch of images with their respective labels\n",
    "def show_samples(loader, batch_size):\n",
    "    rows= batch_size//8\n",
    "    columns = batch_size//rows\n",
    "\n",
    "    for images, labels in loader:\n",
    "        print('images.shape:', images.shape)\n",
    "        plt.figure(figsize=(rows,columns))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(make_grid(images, nrow=rows).permute((1, 2, 0)))\n",
    "        print(labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fde6ce",
   "metadata": {},
   "source": [
    "## get datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c682d427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:47.961128Z",
     "iopub.status.busy": "2022-10-02T15:18:47.960688Z",
     "iopub.status.idle": "2022-10-02T15:18:47.971387Z",
     "shell.execute_reply": "2022-10-02T15:18:47.970672Z",
     "shell.execute_reply.started": "2022-10-02T15:18:47.961093Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(dataset, dataset_save_path, img_size, batch_size):\n",
    "\n",
    "    if dataset == \"cifar10\":\n",
    "        n_classes, img_channels, train_dataset, validation_dataset, test_dataset, classes_weights = get_cifar10(dataset_save_path, img_size)\n",
    "\n",
    "    elif dataset == \"cifar100\":\n",
    "        n_classes, img_channels, train_dataset, validation_dataset, test_dataset, classes_weights = get_cifar100(dataset_save_path, img_size)\n",
    "\n",
    "    elif dataset == \"tiny_imagenet\":\n",
    "        n_classes, img_channels, train_dataset, validation_dataset, test_dataset, classes_weights = get_tiny_imagenet(dataset_save_path, img_size)\n",
    "\n",
    "    elif dataset == \"fashionMNIST\":\n",
    "        n_classes, img_channels, train_dataset, validation_dataset, test_dataset, classes_weights = get_fashionMNIST(dataset_save_path, img_size)\n",
    "\n",
    "    elif dataset == \"eurosatW\":\n",
    "        n_classes, img_channels, train_dataset, validation_dataset, test_dataset, classes_weights = get_eurosat(dataset_save_path, img_size)\n",
    "\n",
    "    elif dataset == \"gtsrbW\":\n",
    "        n_classes, img_channels, train_dataset, validation_dataset, test_dataset, classes_weights = get_gtsrb(dataset_save_path, img_size)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"dataset not implemeneted\")\n",
    "\n",
    "    print(\"training images:\", len(train_dataset))\n",
    "    print(\"validation images:\", len(validation_dataset))\n",
    "    print(\"test images:\", len(test_dataset))\n",
    "\n",
    "    train_loader, validation_loader, test_loader = get_loaders(train_dataset, validation_dataset, test_dataset, batch_size)\n",
    "    #show_samples(train_loader, batch_size)\n",
    "    \n",
    "    return train_loader, validation_loader, test_loader, n_classes, img_channels, classes_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b4ec57",
   "metadata": {},
   "source": [
    "# NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97251e4d",
   "metadata": {},
   "source": [
    "## networks generators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b8f127",
   "metadata": {},
   "source": [
    "### my network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c892c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySENetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, input, stages, exit):\n",
    "\n",
    "        super(MySENetwork,self).__init__()\n",
    "\n",
    "        self.input = input\n",
    "        self.stages = stages\n",
    "        self.exit = exit\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        # pass through input layer\n",
    "        x=self.input(x)\n",
    "        \n",
    "        #pass through stages\n",
    "        for stage in self.stages:\n",
    "            x=stage(x)\n",
    "        \n",
    "        # pass through the only exit\n",
    "        x=self.exit(x)\n",
    "        \n",
    "        # return result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbbe8360",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMENetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, input, stages, exits, exits_positions):\n",
    "\n",
    "        super(MyMENetwork,self).__init__()\n",
    "\n",
    "        assert(len(exits_positions)==len(exits))\n",
    "        self.input = input\n",
    "        self.stages = stages\n",
    "        self.exits = exits\n",
    "        self.exits_positions = exits_positions\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # pass through input layer\n",
    "        x=self.input(x)\n",
    "        \n",
    "        #pass through stages\n",
    "        intermediate_results = []\n",
    "        for stage in self.stages:\n",
    "            x=stage(x)\n",
    "            intermediate_results.append(x)\n",
    "\n",
    "        results = []        \n",
    "        useful_intermediate_results = [intermediate_results[exit_pos-1] for exit_pos in self.exits_positions]\n",
    "        \n",
    "        for x, exit in zip(useful_intermediate_results, self.exits):\n",
    "            x = exit(x)\n",
    "            results.append(x)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def extract_subnetwork(self, selected_exits):\n",
    "    \n",
    "        selected_exits = sorted(selected_exits) # order exits numbers\n",
    "        selected_exits = list(set(selected_exits))  # remove duplicates\n",
    "        \n",
    "        assert min(selected_exits)>=1   # exit number must be at least one\n",
    "        assert max(selected_exits)<=len(self.stages)    # exit number cannot be more than the number of stages\n",
    "        assert isinstance(selected_exits,(list,tuple))  # check is a list\n",
    "        assert (set(selected_exits)).issubset(set(self.exits_positions))    # check that selected exit are among the ones present\n",
    "        \n",
    "        # keep input layer\n",
    "        input = deepcopy(self.input)\n",
    "        \n",
    "        # keep stages only up to last selected exit\n",
    "        last_stage = max(selected_exits) \n",
    "        stages = deepcopy(self.stages)\n",
    "        stages = stages[:last_stage]\n",
    "\n",
    "        # keep only selected exits\n",
    "        exits = nn.ModuleList()\n",
    "        for pos in selected_exits:\n",
    "            exits.append(deepcopy(self.exits[pos-1]))\n",
    "\n",
    "        if len(exits)==1:\n",
    "            return MySENetwork(input,stages,exits[0])\n",
    "        else:\n",
    "            return MyMENetwork(input,stages,exits,selected_exits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1ba430",
   "metadata": {},
   "source": [
    "### resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afd5f23c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:47.973366Z",
     "iopub.status.busy": "2022-10-02T15:18:47.972576Z",
     "iopub.status.idle": "2022-10-02T15:18:47.984898Z",
     "shell.execute_reply": "2022-10-02T15:18:47.983946Z",
     "shell.execute_reply.started": "2022-10-02T15:18:47.973331Z"
    }
   },
   "outputs": [],
   "source": [
    "class NewResnet50Exit(nn.Module):\n",
    "\n",
    "    def __init__(self, features, n_classes):\n",
    "        \n",
    "        super(NewResnet50Exit,self).__init__()\n",
    "        \n",
    "        self.fc = nn.Linear(features, n_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.adaptive_avg_pool2d(x, (1,1))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77b98f17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.002267Z",
     "iopub.status.busy": "2022-10-02T15:18:48.001641Z",
     "iopub.status.idle": "2022-10-02T15:18:48.013235Z",
     "shell.execute_reply": "2022-10-02T15:18:48.012309Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.002225Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_resnet50(is_single_exit, pretrained, n_classes, img_channels):\n",
    "    \n",
    "    model = models.resnet50(pretrained)\n",
    "\n",
    "    input = nn.Sequential(\n",
    "        nn.Conv2d(img_channels, 64, kernel_size=(7,7), stride=(2,2), padding=(3,3), bias=False),\n",
    "        nn.Sequential(*list(model.children())[1:4])\n",
    "    )\n",
    "    \n",
    "    stage1 = list(model.children())[4]\n",
    "    stage2 = list(model.children())[5]\n",
    "    stage3 = list(model.children())[6]\n",
    "    stage4 = list(model.children())[7]\n",
    "    stages = nn.ModuleList([stage1,stage2,stage3,stage4])\n",
    "    \n",
    "    exit4 = NewResnet50Exit(2048, n_classes)\n",
    "    if is_single_exit:\n",
    "        network = MySENetwork(input, stages, exit4)\n",
    "    else: \n",
    "        exit1 = NewResnet50Exit(256, n_classes)\n",
    "        exit2 = NewResnet50Exit(512, n_classes)\n",
    "        exit3 = NewResnet50Exit(1024, n_classes)\n",
    "        exits = nn.ModuleList([exit1,exit2,exit3,exit4])\n",
    "        network = MyMENetwork(input, stages, exits,[1,2,3,4])\n",
    "\n",
    "    n_exits = 4\n",
    "    \n",
    "    return network, n_exits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed37949",
   "metadata": {},
   "source": [
    "### vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edccfa15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.015337Z",
     "iopub.status.busy": "2022-10-02T15:18:48.014951Z",
     "iopub.status.idle": "2022-10-02T15:18:48.023835Z",
     "shell.execute_reply": "2022-10-02T15:18:48.022890Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.015279Z"
    }
   },
   "outputs": [],
   "source": [
    "class NewVgg16Exit(nn.Module):\n",
    "\n",
    "    def __init__(self, features, n_classes):\n",
    "            \n",
    "            super(NewVgg16Exit,self).__init__()\n",
    "            \n",
    "            self.fc = nn.Linear(features, n_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.adaptive_avg_pool2d(x, (1,1))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d8136d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.042550Z",
     "iopub.status.busy": "2022-10-02T15:18:48.042099Z",
     "iopub.status.idle": "2022-10-02T15:18:48.051481Z",
     "shell.execute_reply": "2022-10-02T15:18:48.050429Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.042511Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vgg16(is_single_exit, pretrained, n_classes, img_channels):\n",
    "    \n",
    "    model = models.vgg16(pretrained)\n",
    "    \n",
    "    input = nn.Conv2d(img_channels, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    stage1 = nn.Sequential(*list(model.features.children())[1:10])\n",
    "    stage2 = nn.Sequential(*list(model.features.children())[10:17])\n",
    "    stage3 = nn.Sequential(*list(model.features.children())[17:24])\n",
    "    stage4 = nn.Sequential(*list(model.features.children())[24:])\n",
    "    stages = nn.ModuleList([stage1,stage2,stage3,stage4])\n",
    "\n",
    "    exit4 = NewVgg16Exit(512, n_classes)\n",
    "    if is_single_exit:\n",
    "        network = MySENetwork(input, stages, exit4)\n",
    "    else: \n",
    "        exit1 = NewVgg16Exit(128, n_classes)\n",
    "        exit2 = NewVgg16Exit(256, n_classes)\n",
    "        exit3 = NewVgg16Exit(512, n_classes)\n",
    "        exits = nn.ModuleList([exit1,exit2,exit3,exit4])\n",
    "        network = MyMENetwork(input, stages, exits,[1,2,3,4])\n",
    "\n",
    "    n_exits = 4\n",
    "\n",
    "    return network, n_exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ee4eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg16full(is_single_exit, pretrained, n_classes, img_channels):\n",
    "    \n",
    "    model = models.vgg16(pretrained)\n",
    "    \n",
    "    input = nn.Conv2d(img_channels, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    stage1 = nn.Sequential(*list(model.features.children())[1:5])\n",
    "    stage2 = nn.Sequential(*list(model.features.children())[5:10])\n",
    "    stage3 = nn.Sequential(*list(model.features.children())[10:17])\n",
    "    stage4 = nn.Sequential(*list(model.features.children())[17:24])\n",
    "    stage5 = nn.Sequential(*list(model.features.children())[24:])\n",
    "    stages = nn.ModuleList([stage1,stage2,stage3,stage4,stage5])\n",
    "\n",
    "    exit5 = NewVgg16Exit(512, n_classes)\n",
    "    if is_single_exit:\n",
    "        network = MySENetwork(input, stages, exit5)\n",
    "    else:\n",
    "        exit1 = NewVgg16Exit(64, n_classes)\n",
    "        exit2 = NewVgg16Exit(128, n_classes)\n",
    "        exit3 = NewVgg16Exit(256, n_classes)\n",
    "        exit4 = NewVgg16Exit(512, n_classes)\n",
    "        exits = nn.ModuleList([exit1,exit2,exit3,exit4,exit5])\n",
    "        network = MyMENetwork(input, stages, exits,[1,2,3,4,5])\n",
    "\n",
    "    n_exits = 5\n",
    "\n",
    "    return network, n_exits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0037c437",
   "metadata": {},
   "source": [
    "### densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f62ed5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.053559Z",
     "iopub.status.busy": "2022-10-02T15:18:48.053134Z",
     "iopub.status.idle": "2022-10-02T15:18:48.063759Z",
     "shell.execute_reply": "2022-10-02T15:18:48.062860Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.053525Z"
    }
   },
   "outputs": [],
   "source": [
    "class NewDensenet169Exit(nn.Module):\n",
    "\n",
    "    def __init__(self, fetures, n_classes):\n",
    "        super(NewDensenet169Exit,self).__init__()\n",
    "\n",
    "        self.fc= nn.Linear(fetures,n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1bbe655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.084079Z",
     "iopub.status.busy": "2022-10-02T15:18:48.083569Z",
     "iopub.status.idle": "2022-10-02T15:18:48.094868Z",
     "shell.execute_reply": "2022-10-02T15:18:48.093964Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.084044Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_densenet169(is_single_exit, pretrained, n_classes, img_channels):\n",
    "    \n",
    "    model = models.densenet169(pretrained)\n",
    "    \n",
    "    input = nn.Sequential(\n",
    "        nn.Conv2d(img_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "        nn.Sequential(*list(model.features.children())[1:4])\n",
    "    )\n",
    "    stage1 = nn.Sequential(*list(model.features.children())[4:6])\n",
    "    stage2 = nn.Sequential(*list(model.features.children())[6:8])\n",
    "    stage3 = nn.Sequential(*list(model.features.children())[8:10])\n",
    "    stage4 = nn.Sequential(*list(model.features.children())[10:])\n",
    "    stages = nn.ModuleList([stage1,stage2,stage3,stage4])\n",
    "    \n",
    "    exit4 = NewDensenet169Exit(1664,n_classes)        \n",
    "    if is_single_exit:\n",
    "        network = MySENetwork(input, stages, exit4)\n",
    "    else:      \n",
    "        exit1 = NewDensenet169Exit(128,n_classes)\n",
    "        exit2 = NewDensenet169Exit(256,n_classes)\n",
    "        exit3 = NewDensenet169Exit(640,n_classes)\n",
    "        exits = nn.ModuleList([exit1,exit2,exit3,exit4])\n",
    "        network = MyMENetwork(input, stages, exits,[1,2,3,4])\n",
    "\n",
    "    n_exits = 4\n",
    "\n",
    "    return network, n_exits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea00a4",
   "metadata": {},
   "source": [
    "### mbv3small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "764807f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.096997Z",
     "iopub.status.busy": "2022-10-02T15:18:48.096646Z",
     "iopub.status.idle": "2022-10-02T15:18:48.107256Z",
     "shell.execute_reply": "2022-10-02T15:18:48.106353Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.096962Z"
    }
   },
   "outputs": [],
   "source": [
    "class NewMbv3smallExit(nn.Module):\n",
    "\n",
    "    def __init__(self, features, n_classes):\n",
    "        \n",
    "        super(NewMbv3smallExit,self).__init__()\n",
    "        \n",
    "        int1_features= features*6\n",
    "        int2_features= int(features* 1.75)\n",
    "        \n",
    "        self.convnorm = nn.Sequential (\n",
    "            nn.Conv2d(features, int1_features, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(int1_features, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
    "            nn.Hardswish(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.exit = nn.Sequential(\n",
    "            nn.Linear(int1_features, int2_features, bias=True),\n",
    "            nn.Hardswish(inplace=True),\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(int2_features, n_classes, bias=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.convnorm(x)\n",
    "        x = F.adaptive_avg_pool2d(x,(1,1))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.exit(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85b848f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.130504Z",
     "iopub.status.busy": "2022-10-02T15:18:48.129146Z",
     "iopub.status.idle": "2022-10-02T15:18:48.142011Z",
     "shell.execute_reply": "2022-10-02T15:18:48.141091Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.130460Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mobilenetv3small(is_single_exit, pretrained, n_classes, img_channels):\n",
    "    \n",
    "    model = models.mobilenet_v3_small(pretrained)\n",
    "        \n",
    "    input = nn.Sequential(\n",
    "        nn.Conv2d(img_channels, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "        nn.BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
    "        nn.Hardswish(inplace=True)\n",
    "    )\n",
    "\n",
    "    stage1 = nn.Sequential(*list(model.features.children())[1:4])\n",
    "    stage2 = nn.Sequential(*list(model.features.children())[4:7])\n",
    "    stage3 = nn.Sequential(*list(model.features.children())[7:9])\n",
    "    stage4 = nn.Sequential(*list(model.features.children())[9:12])\n",
    "    stages = nn.ModuleList([stage1,stage2,stage3,stage4])\n",
    "\n",
    "    exit4 = NewMbv3smallExit(96,n_classes)\n",
    "    if is_single_exit:\n",
    "        network = MySENetwork(input, stages, exit4)\n",
    "    else:\n",
    "        exit1 = NewMbv3smallExit(24,n_classes)\n",
    "        exit2 = NewMbv3smallExit(40,n_classes)\n",
    "        exit3 = NewMbv3smallExit(48,n_classes)\n",
    "        exits = nn.ModuleList([exit1,exit2,exit3,exit4])\n",
    "        network = MyMENetwork(input, stages, exits,[1,2,3,4])\n",
    "\n",
    "    n_exits = 4\n",
    "\n",
    "    return network, n_exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b6a0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobilenetv3smallfull(is_single_exit, pretrained, n_classes, img_channels):\n",
    "    \n",
    "    model = models.mobilenet_v3_small(pretrained)\n",
    "        \n",
    "    input = nn.Sequential(\n",
    "        nn.Conv2d(img_channels, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "        nn.BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
    "        nn.Hardswish(inplace=True)\n",
    "    )\n",
    "\n",
    "    stage1 = list(model.features.children())[1]\n",
    "    stage2 = nn.Sequential(*list(model.features.children())[2:4])\n",
    "    stage3 = nn.Sequential(*list(model.features.children())[4:7])\n",
    "    stage4 = nn.Sequential(*list(model.features.children())[7:9])\n",
    "    stage5 = nn.Sequential(*list(model.features.children())[9:12])\n",
    "    stages = nn.ModuleList([stage1,stage2,stage3,stage4,stage5])\n",
    "\n",
    "    exit5 = NewMbv3smallExit(96,n_classes) \n",
    "    if is_single_exit:\n",
    "        network = MySENetwork(input, stages, exit5)\n",
    "    else:\n",
    "        exit1 = NewMbv3smallExit(16,n_classes)\n",
    "        exit2 = NewMbv3smallExit(24,n_classes)\n",
    "        exit3 = NewMbv3smallExit(40,n_classes)\n",
    "        exit4 = NewMbv3smallExit(48,n_classes) \n",
    "        exits = nn.ModuleList([exit1,exit2,exit3,exit4,exit5])\n",
    "        network = MyMENetwork(input, stages, exits,[1,2,3,4,5])\n",
    "\n",
    "    n_exits = 5\n",
    "\n",
    "    return network, n_exits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363cefed",
   "metadata": {},
   "source": [
    "### efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07e5a7fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.144128Z",
     "iopub.status.busy": "2022-10-02T15:18:48.143632Z",
     "iopub.status.idle": "2022-10-02T15:18:48.154782Z",
     "shell.execute_reply": "2022-10-02T15:18:48.153856Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.144093Z"
    }
   },
   "outputs": [],
   "source": [
    "class NewEffB5Exit(nn.Module):\n",
    "\n",
    "    def __init__(self, features, n_classes):\n",
    "        \n",
    "        super(NewEffB5Exit,self).__init__()\n",
    "\n",
    "        intermediate_features = features * 4\n",
    "        \n",
    "        self.convNomrAct = nn.Sequential(\n",
    "            nn.Conv2d(features, intermediate_features, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(intermediate_features, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
    "            nn.SiLU(inplace=True)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.4, inplace=True),\n",
    "            nn.Linear(in_features=intermediate_features, out_features=n_classes, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x= self.convNomrAct(x)\n",
    "        x=F.adaptive_avg_pool2d(x,(1,1))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x= self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dc8cdc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.172843Z",
     "iopub.status.busy": "2022-10-02T15:18:48.172039Z",
     "iopub.status.idle": "2022-10-02T15:18:48.183628Z",
     "shell.execute_reply": "2022-10-02T15:18:48.183013Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.172806Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_efficientnetB5(is_single_exit, pretrained, n_classes, img_channels):\n",
    "\n",
    "    model = models.efficientnet_b5(pretrained)\n",
    "\n",
    "    input = nn.Sequential(\n",
    "        nn.Conv2d(img_channels, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "        nn.BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
    "        nn.SiLU(inplace=True)\n",
    "    )\n",
    "\n",
    "    stage1 = nn.Sequential(*list(model.features.children())[1:3])\n",
    "    stage2 = nn.Sequential(*list(model.features.children())[3:5])\n",
    "    stage3 = nn.Sequential(*list(model.features.children())[5:6])\n",
    "    stage4 = nn.Sequential(*list(model.features.children())[6:8])\n",
    "    stages = nn.ModuleList([stage1,stage2,stage3,stage4])\n",
    "\n",
    "    exit4 = NewEffB5Exit(512,n_classes)\n",
    "    if is_single_exit:\n",
    "        network = MySENetwork(input, stages, exit4)\n",
    "    else:\n",
    "        exit1 = NewEffB5Exit(40,n_classes)\n",
    "        exit2 = NewEffB5Exit(128,n_classes)\n",
    "        exit3 = NewEffB5Exit(176,n_classes)\n",
    "        exits = nn.ModuleList([exit1,exit2,exit3,exit4])\n",
    "        network = MyMENetwork(input, stages, exits,[1,2,3,4])\n",
    "\n",
    "    n_exits = 4\n",
    "\n",
    "    return network, n_exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "905798c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_efficientnetB5full(is_single_exit, pretrained, n_classes, img_channels):\n",
    "\n",
    "    model = models.efficientnet_b5(pretrained)\n",
    "\n",
    "    input = nn.Sequential(\n",
    "        nn.Conv2d(img_channels, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "        nn.BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
    "        nn.SiLU(inplace=True)\n",
    "    )\n",
    "\n",
    "    stage1 = nn.Sequential(*list(model.features.children())[1])\n",
    "    stage2 = nn.Sequential(*list(model.features.children())[2])\n",
    "    stage3 = nn.Sequential(*list(model.features.children())[3])\n",
    "    stage4 = nn.Sequential(*list(model.features.children())[4])\n",
    "    stage5 = nn.Sequential(*list(model.features.children())[5])\n",
    "    stage6 = nn.Sequential(*list(model.features.children())[6])\n",
    "    stage7 = nn.Sequential(*list(model.features.children())[7])\n",
    "    stages = nn.ModuleList([stage1,stage2,stage3,stage4,stage5,stage6,stage7])\n",
    "\n",
    "    exit7 = NewEffB5Exit(512,n_classes)  \n",
    "    if is_single_exit:\n",
    "        network = MySENetwork(input, stages, exit7)\n",
    "    else:\n",
    "        exit1 = NewEffB5Exit(24,n_classes)\n",
    "        exit2 = NewEffB5Exit(40,n_classes)\n",
    "        exit3 = NewEffB5Exit(64,n_classes)\n",
    "        exit4 = NewEffB5Exit(128,n_classes)\n",
    "        exit5 = NewEffB5Exit(176,n_classes)\n",
    "        exit6 = NewEffB5Exit(304,n_classes)\n",
    "        exits = nn.ModuleList([exit1,exit2,exit3,exit4,exit5,exit6,exit7])\n",
    "        network = MyMENetwork(input, stages, exits,[1,2,3,4,5,6,7])\n",
    "\n",
    "    n_exits = 7\n",
    "\n",
    "    return network, n_exits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb4545",
   "metadata": {},
   "source": [
    "## get networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc8393d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.190765Z",
     "iopub.status.busy": "2022-10-02T15:18:48.189995Z",
     "iopub.status.idle": "2022-10-02T15:18:48.198555Z",
     "shell.execute_reply": "2022-10-02T15:18:48.197548Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.190735Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_network(network_name, is_single_exit, pretrained, n_classes, img_channels):\n",
    "    \n",
    "    if network_name == \"resnet50\":\n",
    "        network, n_exits = get_resnet50(is_single_exit, pretrained, n_classes, img_channels)\n",
    "    #------------------------------------------------------------------------------------------------\n",
    "    elif network_name == \"vgg16\":\n",
    "        network, n_exits = get_vgg16(is_single_exit, pretrained, n_classes, img_channels)\n",
    "    elif network_name == \"vgg16full\":\n",
    "        network, n_exits = get_vgg16full(is_single_exit, pretrained, n_classes, img_channels)\n",
    "    #------------------------------------------------------------------------------------------------  \n",
    "    elif network_name == \"densenet169\":\n",
    "        network, n_exits = get_densenet169(is_single_exit, pretrained, n_classes, img_channels)\n",
    "    #------------------------------------------------------------------------------------------------\n",
    "    elif network_name == \"mobilenetv3small\":\n",
    "        network, n_exits = get_mobilenetv3small(is_single_exit, pretrained, n_classes, img_channels)\n",
    "    elif network_name == \"mobilenetv3smallfull\":\n",
    "        network, n_exits = get_mobilenetv3smallfull(is_single_exit, pretrained, n_classes, img_channels)\n",
    "    #------------------------------------------------------------------------------------------------\n",
    "    elif network_name == \"efficientnetB5\":\n",
    "        network, n_exits = get_efficientnetB5(is_single_exit, pretrained, n_classes, img_channels)\n",
    "    elif network_name == \"efficientnetB5full\":\n",
    "        network, n_exits = get_efficientnetB5full(is_single_exit, pretrained, n_classes, img_channels)\n",
    "    #------------------------------------------------------------------------------------------------\n",
    "    else:\n",
    "        raise ValueError(\"network not implemeneted\")\n",
    "        \n",
    "    return network, n_exits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751e8aa",
   "metadata": {
    "papermill": {
     "duration": 0.82894,
     "end_time": "2022-06-28T15:08:47.741718",
     "exception": false,
     "start_time": "2022-06-28T15:08:46.912778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba6c6359",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.200782Z",
     "iopub.status.busy": "2022-10-02T15:18:48.200126Z",
     "iopub.status.idle": "2022-10-02T15:18:48.211657Z",
     "shell.execute_reply": "2022-10-02T15:18:48.210723Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.200746Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metric_dict():\n",
    "    return {\n",
    "        'top1': AverageMeter(),\n",
    "        'top5': AverageMeter(),\n",
    "    }\n",
    "\n",
    "\n",
    "def update_metric(metric_dict, output, labels):\n",
    "    acc1, acc5 = accuracy(output, labels, topk=(1, 5))\n",
    "    metric_dict['top1'].update(acc1[0].item(), output.size(0))\n",
    "    metric_dict['top5'].update(acc5[0].item(), output.size(0))\n",
    "\n",
    "\n",
    "def get_metric_vals(metric_dict, return_dict=False):\n",
    "    if return_dict:\n",
    "        return {key: metric_dict[key].avg for key in metric_dict}\n",
    "    else:\n",
    "        return [metric_dict[key].avg for key in metric_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d0902",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bb277ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.214022Z",
     "iopub.status.busy": "2022-10-02T15:18:48.213269Z",
     "iopub.status.idle": "2022-10-02T15:18:48.221130Z",
     "shell.execute_reply": "2022-10-02T15:18:48.220207Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.213974Z"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStoppingMeter:\n",
    "\n",
    "    def __init__(self, patience = 12):\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.patience=patience\n",
    "        self.stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "\n",
    "        if self.best_loss is None or self.best_loss>val_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter +=1\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1989bee5",
   "metadata": {},
   "source": [
    "# Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4652f121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.223095Z",
     "iopub.status.busy": "2022-10-02T15:18:48.222509Z",
     "iopub.status.idle": "2022-10-02T15:18:48.232645Z",
     "shell.execute_reply": "2022-10-02T15:18:48.231802Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.223060Z"
    },
    "papermill": {
     "duration": 0.021457,
     "end_time": "2022-06-28T15:08:47.812812",
     "exception": false,
     "start_time": "2022-06-28T15:08:47.791355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_output_se(phase, epoch, epochs, loss, top1, top5, time, log_file):\n",
    "    \n",
    "    output = phase.upper()+\": \" #TRAINING/VALIDATION/TESTING\n",
    "    output += f\"Epoch [{epoch}/{epochs}], Loss: {loss:.3f}, top1:{top1:.3f}, top5:{top5:.3f}, time:{time:.1f}s\"\n",
    "    \n",
    "    \n",
    "    if phase.lower() == \"validation\":\n",
    "        output += \"\\n--------------------------------------------------------------------------\"\n",
    "    \n",
    "    print(output)\n",
    "    \n",
    "    with open(log_file,\"a\") as log:\n",
    "        log.write(\"\\n\"+output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75d3f13d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.235577Z",
     "iopub.status.busy": "2022-10-02T15:18:48.234919Z",
     "iopub.status.idle": "2022-10-02T15:18:48.245897Z",
     "shell.execute_reply": "2022-10-02T15:18:48.245255Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.235542Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_output_ee(phase, epoch, epochs, net_loss, branches_loss, net_top1, net_top5, branches_top1, branches_top5, time, log_file):\n",
    "    \n",
    "    output = phase.upper()+\": \" #TRAINING/VALIDATION/TESTING\n",
    "    output += f\"Epoch [{epoch}/{epochs}], Net Loss: {net_loss:.3f}, Net top1:{net_top1:.3f}, Net top5:{net_top5:.3f}, time:{time:.1f}s\\n\"\n",
    "    \n",
    "    # format the lists of values (branches losses and accuracies)\n",
    "    br_loss_str= \"[\"\n",
    "    br_top1_str = \"[\"\n",
    "    br_top5_str = \"[\"\n",
    "    for bl,bt1,bt5 in zip(branches_loss, branches_top1, branches_top5):\n",
    "        br_loss_str += f\" {bl:.3f} |\"\n",
    "        br_top1_str += f\" {bt1:.3f} |\"\n",
    "        br_top5_str += f\" {bt5:.3f} |\"\n",
    "    br_loss_str = br_loss_str[:-1]+\"]\"\n",
    "    br_top1_str = br_top1_str[:-1]+\"]\"\n",
    "    br_top5_str = br_top5_str[:-1]+\"]\"\n",
    "    \n",
    "    output += \"Branches losses = \" + br_loss_str +\"\\n\"\n",
    "    output += \"Branches top1 = \"+ br_top1_str+\"\\n\"\n",
    "    output += \"Branches top5 = \"+ br_top5_str\n",
    "\n",
    "    if phase.lower() == \"validation\":\n",
    "        output += \"\\n--------------------------------------------------------------------------\"\n",
    "    \n",
    "    print(output)\n",
    "    \n",
    "    with open(log_file,\"a\") as log:\n",
    "        log.write(\"\\n\"+output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eb00e4",
   "metadata": {},
   "source": [
    "## PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9ad754f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.247923Z",
     "iopub.status.busy": "2022-10-02T15:18:48.247294Z",
     "iopub.status.idle": "2022-10-02T15:18:48.256103Z",
     "shell.execute_reply": "2022-10-02T15:18:48.255499Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.247888Z"
    },
    "papermill": {
     "duration": 0.020709,
     "end_time": "2022-06-28T15:08:48.066451",
     "exception": false,
     "start_time": "2022-06-28T15:08:48.045742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_plot(epochs,train_values,valid_values,output_path, loss_or_acc, title):\n",
    "    \n",
    "    extension = title+\".png\"\n",
    "    save_path=os.path.join(output_path,extension)\n",
    "    \n",
    "    x = np.arange(1, epochs+1)\n",
    "    c = \"r\" if loss_or_acc == \"loss\" else \"b\"\n",
    "    \n",
    "    plt.plot(x, train_values, color=c, label=\"train \"+ loss_or_acc, linestyle=\"solid\")\n",
    "    plt.plot(x, valid_values, color=c, label=\"valid \"+ loss_or_acc, linestyle=\"dashed\")\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.savefig(save_path)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3874c56e",
   "metadata": {},
   "source": [
    "# TRAINING AND TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb783ae",
   "metadata": {},
   "source": [
    "### ENSEMBLE VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_len(bin_str,expected_len):\n",
    "    pad = expected_len - len(bin_str)\n",
    "    bin_str = \"0\"*pad + bin_str\n",
    "    return bin_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6136379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_binary_strings(n):\n",
    "    bin_str_len=int(math.log2(n))\n",
    "    bin_str_list =[]\n",
    "    for i in range(0,n):\n",
    "        bin_str = \"{0:b}\".format(i)\n",
    "        bin_str_list.append(fix_len(bin_str,bin_str_len))\n",
    "    \n",
    "    return bin_str_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_all_ensembles(network, device, loader, ensemble_weights):\n",
    "\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # keep track of acc perfromances for all ensembles\n",
    "        n_exits = len(ensemble_weights)\n",
    "        binary_strings=generate_binary_strings(2**n_exits)\n",
    "        n_ensembles = len(binary_strings)\n",
    "\n",
    "        ensembles_metric_dicts = []\n",
    "        for _ in range(n_ensembles):\n",
    "            ensembles_metric_dicts.append(get_metric_dict())\n",
    "         \n",
    "        for _, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = network(images)            \n",
    "            \n",
    "            weighted_outputs=[]\n",
    "            for output,weight in zip(outputs,ensemble_weights):\n",
    "                weighted_outputs.append(output * weight)\n",
    "\n",
    "            ensemble_outputs=[]\n",
    "            for binary_string in binary_strings:\n",
    "                active_weighted_outputs = []\n",
    "                for bit, weighted_output in zip(binary_string,weighted_outputs):\n",
    "                    if bit == \"1\":\n",
    "                        active_weighted_outputs.append(weighted_output)\n",
    "\n",
    "                if len(active_weighted_outputs)>1:\n",
    "                    ensemble_output=torch.stack(active_weighted_outputs)\n",
    "                    ensemble_output=torch.sum(ensemble_output,dim=0)\n",
    "                else:\n",
    "                    ensemble_output=active_weighted_outputs[0]\n",
    "\n",
    "                ensemble_outputs.append(ensemble_output)\n",
    "\n",
    "            # update metrics\n",
    "            \n",
    "            for ensemble_output, ensemble_metric_dict in zip(ensemble_outputs, ensembles_metric_dicts):\n",
    "                update_metric(ensemble_metric_dict, ensemble_output, labels)\n",
    "\n",
    "        ensembles_dict = {}\n",
    "        for ensemble_metric_dict, binary_string in zip (ensembles_metric_dicts, binary_strings):\n",
    "            ensembles_dict[binary_string] = get_metric_vals(ensemble_metric_dict, return_dict=False)\n",
    "        \n",
    "        return ensembles_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ae9da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_subnet_se(network, device, loader):\n",
    "\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        metric_dict=get_metric_dict()\n",
    "        \n",
    "        start = time.time()\n",
    "        for _, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = network(images)\n",
    "            \n",
    "            # update metrics\n",
    "            update_metric(metric_dict, output, labels)\n",
    "            \n",
    "        time_passed= time.time()-start \n",
    "        \n",
    "    return get_metric_vals(metric_dict), time_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a015a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_subnet_ee(network, device, loader, ensemble_weights):\n",
    "\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        net_metric_dict=get_metric_dict()\n",
    "        \n",
    "        start = time.time()\n",
    "        for _, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = network(images)\n",
    "                \n",
    "            weighted_outputs=[]\n",
    "            for output,weight in zip(outputs,ensemble_weights):\n",
    "                weighted_outputs.append(output * weight)\n",
    "\n",
    "            net_output=torch.stack(weighted_outputs)\n",
    "            net_output=torch.sum(net_output,dim=0)\n",
    "\n",
    "            # update metrics\n",
    "            update_metric(net_metric_dict, net_output, labels)\n",
    "\n",
    "        time_passed= time.time()-start \n",
    "        \n",
    "        return get_metric_vals(net_metric_dict), time_passed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61035104",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db79d282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.258138Z",
     "iopub.status.busy": "2022-10-02T15:18:48.257529Z",
     "iopub.status.idle": "2022-10-02T15:18:48.266256Z",
     "shell.execute_reply": "2022-10-02T15:18:48.265568Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.258094Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate_se(network, device, criterion, loader):\n",
    "\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        losses = AverageMeter()\n",
    "        metric_dict=get_metric_dict()\n",
    "        \n",
    "        start = time.time()\n",
    "        for _, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = network(images)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            # update metrics\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            update_metric(metric_dict, output, labels)\n",
    "            \n",
    "        time_passed= time.time()-start \n",
    "        \n",
    "    return losses.avg, get_metric_vals(metric_dict), time_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c88263e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.268339Z",
     "iopub.status.busy": "2022-10-02T15:18:48.267698Z",
     "iopub.status.idle": "2022-10-02T15:18:48.282296Z",
     "shell.execute_reply": "2022-10-02T15:18:48.281373Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.268304Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate_ee(network, device, criterion, loader, branches_weights, ensemble_weights):\n",
    "\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        net_losses = AverageMeter()\n",
    "        net_metric_dict=get_metric_dict()\n",
    "\n",
    "        branches_losses_meter = []\n",
    "        branches_metric_dict = []\n",
    "        for _ in range(len(branches_weights)):\n",
    "            branches_losses_meter.append(AverageMeter())\n",
    "            branches_metric_dict.append(get_metric_dict())\n",
    "         \n",
    "        \n",
    "        start = time.time()\n",
    "        for _, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = network(images)\n",
    "            branches_losses = [criterion(output, labels) for output in outputs]\n",
    "\n",
    "            net_loss = 0\n",
    "            weighted_losses = []\n",
    "            for branch_loss, weight in zip(branches_losses,branches_weights):\n",
    "                wl = branch_loss * weight\n",
    "                weighted_losses.append(wl)\n",
    "                net_loss += wl\n",
    "                \n",
    "\n",
    "            weighted_outputs=[]\n",
    "            for output,weight in zip(outputs,ensemble_weights):\n",
    "                weighted_outputs.append(output * weight)\n",
    "\n",
    "            net_output=torch.stack(weighted_outputs)\n",
    "            net_output=torch.sum(net_output,dim=0)\n",
    "\n",
    "            # update metrics\n",
    "            net_losses.update(net_loss.item(), images.size(0))\n",
    "            update_metric(net_metric_dict, net_output, labels)\n",
    "\n",
    "            for weighted_loss, branch_loss_meter in zip(weighted_losses, branches_losses_meter):\n",
    "                branch_loss_meter.update(weighted_loss.item(), images.size(0))\n",
    "\n",
    "            for output, br_metric_dict in zip(outputs, branches_metric_dict):\n",
    "                update_metric(br_metric_dict, output, labels)\n",
    "\n",
    "\n",
    "        time_passed= time.time()-start \n",
    "\n",
    "        net_losses_avg = net_losses.avg\n",
    "        net_metric_list_vals = get_metric_vals(net_metric_dict, return_dict=False)\n",
    "        branches_losses_avgs = [branch_loss_meter.avg for branch_loss_meter in branches_losses_meter]\n",
    "        branches_metric_list_vals = [get_metric_vals(br_metric_dict) for br_metric_dict in branches_metric_dict]\n",
    "        br_top1s = [tops[0] for tops in branches_metric_list_vals]\n",
    "        br_top5s = [tops[1] for tops in branches_metric_list_vals]\n",
    "        branches_metric_list_vals = [br_top1s, br_top5s]\n",
    "        \n",
    "        return net_losses_avg, branches_losses_avgs, net_metric_list_vals, branches_metric_list_vals, time_passed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6427c1",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f241f9ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.284879Z",
     "iopub.status.busy": "2022-10-02T15:18:48.284042Z",
     "iopub.status.idle": "2022-10-02T15:18:48.295650Z",
     "shell.execute_reply": "2022-10-02T15:18:48.294735Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.284843Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch_se(network, device, criterion, optimizer, train_loader):\n",
    "\n",
    "    network.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    metric_dict=get_metric_dict()\n",
    "    \n",
    "    start = time.time()\n",
    "    for _, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        output = network(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        update_metric(metric_dict, output, labels)\n",
    "\n",
    "        #backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    time_passed= time.time()-start \n",
    "        \n",
    "    return losses.avg, get_metric_vals(metric_dict), time_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73390089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.297822Z",
     "iopub.status.busy": "2022-10-02T15:18:48.297205Z",
     "iopub.status.idle": "2022-10-02T15:18:48.306386Z",
     "shell.execute_reply": "2022-10-02T15:18:48.305452Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.297788Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_history_se(history,train_loss, train_top1, train_top5, valid_loss, valid_top1, valid_top5):\n",
    "    \n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_top1\"].append(train_top1)\n",
    "    history[\"train_top5\"].append(train_top5)\n",
    "    history[\"valid_loss\"].append(valid_loss)\n",
    "    history[\"valid_top1\"].append(valid_top1)\n",
    "    history[\"valid_top5\"].append(valid_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c77790ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.309756Z",
     "iopub.status.busy": "2022-10-02T15:18:48.309402Z",
     "iopub.status.idle": "2022-10-02T15:18:48.320498Z",
     "shell.execute_reply": "2022-10-02T15:18:48.319620Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.309730Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_se(network, device, train_criterion, valid_criterion, optimizer, epochs, train_loader, validation_loader, output_path, log_file):\n",
    "    \n",
    "    early_stopping = EarlyStoppingMeter()\n",
    "    best_acc = None\n",
    "    best_ckpt_pth = os.path.join(output_path,\"best_ckpt.pth\")\n",
    "    best_model_pth = os.path.join(output_path,\"best_model.pth\")\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\":[],\n",
    "        \"train_top1\":[],\n",
    "        \"train_top5\":[],\n",
    "        \"valid_loss\":[],\n",
    "        \"valid_top1\":[],\n",
    "        \"valid_top5\":[]\n",
    "    }\n",
    "\n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "\n",
    "        train_loss, (train_top1, train_top5), train_time = train_one_epoch_se(network, device, train_criterion, optimizer, train_loader)\n",
    "        log_output_se(\"training\", epoch, epochs, train_loss, train_top1, train_top5, train_time, log_file)\n",
    "        \n",
    "        valid_loss, (valid_top1, valid_top5), valid_time = validate_se(network, device, valid_criterion, validation_loader)\n",
    "        log_output_se(\"validation\", epoch, epochs, valid_loss, valid_top1, valid_top5, valid_time, log_file)\n",
    "\n",
    "        if best_acc is None or valid_top1>best_acc:\n",
    "            best_acc = valid_top1\n",
    "            torch.save(network.state_dict(),best_ckpt_pth)\n",
    "            torch.save(network,best_model_pth)\n",
    "\n",
    "        update_history_se(history,train_loss, train_top1, train_top5, valid_loss, valid_top1, valid_top5)\n",
    "\n",
    "        early_stopping(valid_loss)\n",
    "        if early_stopping.stop:\n",
    "            break\n",
    "\n",
    "    return history, best_model_pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cbdf061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.322640Z",
     "iopub.status.busy": "2022-10-02T15:18:48.322263Z",
     "iopub.status.idle": "2022-10-02T15:18:48.337250Z",
     "shell.execute_reply": "2022-10-02T15:18:48.336220Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.322607Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch_ee(network, device, criterion, optimizer, train_loader, branches_weights, ensemble_weights):\n",
    "\n",
    "    network.train()\n",
    "        \n",
    "    net_losses = AverageMeter()\n",
    "    net_metric_dict=get_metric_dict()\n",
    "\n",
    "    branches_losses_meter = []\n",
    "    branches_metric_dict = []\n",
    "    for _ in range(len(branches_weights)):\n",
    "        branches_losses_meter.append(AverageMeter())\n",
    "        branches_metric_dict.append(get_metric_dict())\n",
    "        \n",
    "    \n",
    "    start = time.time()\n",
    "    for _, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = network(images)\n",
    "        branches_losses = [criterion(output, labels) for output in outputs]\n",
    "\n",
    "        net_loss = 0\n",
    "        weighted_losses = []\n",
    "        for branch_loss, weight in zip(branches_losses,branches_weights):\n",
    "            wl = branch_loss * weight\n",
    "            weighted_losses.append(wl)\n",
    "            net_loss += wl\n",
    "            \n",
    "\n",
    "        weighted_outputs=[]\n",
    "        for output,weight in zip(outputs,ensemble_weights):\n",
    "            weighted_outputs.append(output * weight)\n",
    "\n",
    "        net_output=torch.stack(weighted_outputs)\n",
    "        net_output=torch.sum(net_output,dim=0)\n",
    "\n",
    "        #backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        net_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update metrics\n",
    "        net_losses.update(net_loss.item(), images.size(0))\n",
    "        update_metric(net_metric_dict, net_output, labels)\n",
    "\n",
    "        for weighted_loss, branch_loss_meter in zip(weighted_losses, branches_losses_meter):\n",
    "            branch_loss_meter.update(weighted_loss.item(), images.size(0))\n",
    "\n",
    "        for output, br_metric_dict in zip(outputs, branches_metric_dict):\n",
    "            update_metric(br_metric_dict, output, labels)\n",
    "\n",
    "\n",
    "    time_passed= time.time()-start \n",
    "\n",
    "    net_losses_avg = net_losses.avg\n",
    "    net_metric_list_vals = get_metric_vals(net_metric_dict, return_dict=False)\n",
    "    branches_losses_avgs = [branch_loss_meter.avg for branch_loss_meter in branches_losses_meter]\n",
    "    branches_metric_list_vals = [get_metric_vals(br_metric_dict) for br_metric_dict in branches_metric_dict]\n",
    "    br_top1s = [tops[0] for tops in branches_metric_list_vals]\n",
    "    br_top5s = [tops[1] for tops in branches_metric_list_vals]\n",
    "    branches_metric_list_vals = [br_top1s, br_top5s]\n",
    "    \n",
    "    return net_losses_avg, branches_losses_avgs, net_metric_list_vals, branches_metric_list_vals, time_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "692da6e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.338603Z",
     "iopub.status.busy": "2022-10-02T15:18:48.338362Z",
     "iopub.status.idle": "2022-10-02T15:18:48.349368Z",
     "shell.execute_reply": "2022-10-02T15:18:48.348311Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.338580Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_history_ee(history,tr_net_loss, tr_branches_losses, tr_net_top1, tr_net_top5, tr_branches_top1,tr_branches_top5,v_net_loss, v_branches_loss, v_net_top1, v_net_top5, v_branches_top1, v_branches_top5):\n",
    "    \n",
    "    history[\"train_net_loss\"].append(tr_net_loss)\n",
    "    history[\"train_branches_losses\"].append(tr_branches_losses)\n",
    "    history[\"train_net_top1\"].append(tr_net_top1)\n",
    "    history[\"train_net_top5\"].append(tr_net_top5)\n",
    "    history[\"train_branches_top1\"].append(tr_branches_top1)\n",
    "    history[\"train_branches_top5\"].append(tr_branches_top5)\n",
    "    \n",
    "    history[\"valid_net_loss\"].append(v_net_loss)\n",
    "    history[\"valid_branches_losses\"].append(v_branches_loss)\n",
    "    history[\"valid_net_top1\"].append(v_net_top1)\n",
    "    history[\"valid_net_top5\"].append(v_net_top5)\n",
    "    history[\"valid_branches_top1\"].append(v_branches_top1)\n",
    "    history[\"valid_branches_top5\"].append(v_branches_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73138fbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.351807Z",
     "iopub.status.busy": "2022-10-02T15:18:48.351172Z",
     "iopub.status.idle": "2022-10-02T15:18:48.362933Z",
     "shell.execute_reply": "2022-10-02T15:18:48.362220Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.351773Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_ee(network, device, train_criterion, valid_criterion, optimizer, epochs, train_loader, validation_loader, output_path, log_file, branches_weights, ensemble_weights):\n",
    "\n",
    "    early_stopping = EarlyStoppingMeter()\n",
    "    best_acc = None\n",
    "    best_ckpt_pth = os.path.join(output_path,\"best_ckpt.pth\")\n",
    "    best_model_pth = os.path.join(output_path,\"best_model.pth\")\n",
    "\n",
    "    history = {\n",
    "        \"train_net_loss\":[],\n",
    "        \"train_branches_losses\":[],\n",
    "        \"train_net_top1\":[],\n",
    "        \"train_net_top5\":[],\n",
    "        \"train_branches_top1\":[],\n",
    "        \"train_branches_top5\":[],\n",
    "        \"valid_net_loss\":[],\n",
    "        \"valid_branches_losses\":[],\n",
    "        \"valid_net_top1\":[],\n",
    "        \"valid_net_top5\":[],\n",
    "        \"valid_branches_top1\":[],\n",
    "        \"valid_branches_top5\":[]\n",
    "    } \n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "\n",
    "        tr_net_loss, tr_branches_losses, (tr_net_top1, tr_net_top5), (tr_branches_top1,tr_branches_top5), tr_time = train_one_epoch_ee(network, device, train_criterion, optimizer, train_loader,branches_weights, ensemble_weights)\n",
    "        log_output_ee(\"training\", epoch, epochs, tr_net_loss, tr_branches_losses, tr_net_top1, tr_net_top5, tr_branches_top1,tr_branches_top5, tr_time, log_file)\n",
    "\n",
    "        v_net_loss, v_branches_loss, (v_net_top1, v_net_top5), (v_branches_top1, v_branches_top5), v_time = validate_ee(network, device, valid_criterion, validation_loader, branches_weights,ensemble_weights)\n",
    "        log_output_ee(\"validation\", epoch, epochs, v_net_loss, v_branches_loss, v_net_top1, v_net_top5, v_branches_top1, v_branches_top5, v_time, log_file) \n",
    "\n",
    "        if best_acc is None or v_net_top1>best_acc:\n",
    "            best_acc = v_net_top1\n",
    "            torch.save(network.state_dict(),best_ckpt_pth)\n",
    "            torch.save(network,best_model_pth)\n",
    "\n",
    "        update_history_ee(history,tr_net_loss, tr_branches_losses, tr_net_top1, tr_net_top5, tr_branches_top1,tr_branches_top5,v_net_loss, v_branches_loss, v_net_top1, v_net_top5, v_branches_top1, v_branches_top5)\n",
    "\n",
    "        early_stopping(v_net_loss)\n",
    "        if early_stopping.stop:\n",
    "            break\n",
    "\n",
    "    return history, best_model_pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a2d02b",
   "metadata": {},
   "source": [
    "## network metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67c1388a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.364881Z",
     "iopub.status.busy": "2022-10-02T15:18:48.364259Z",
     "iopub.status.idle": "2022-10-02T15:18:48.376245Z",
     "shell.execute_reply": "2022-10-02T15:18:48.375563Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.364846Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_params(network):\n",
    "    params = sum(p.numel() for p in network.parameters() if p.requires_grad)\n",
    "    return  params / 1e6    #Mparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "946a4010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.378219Z",
     "iopub.status.busy": "2022-10-02T15:18:48.377580Z",
     "iopub.status.idle": "2022-10-02T15:18:48.385828Z",
     "shell.execute_reply": "2022-10-02T15:18:48.385115Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.378160Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_macs(network, dummy_data):\n",
    "    macs = profile_macs(network, dummy_data)\n",
    "    return macs / 1e6  # in unit of Mmacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63eca346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.387784Z",
     "iopub.status.busy": "2022-10-02T15:18:48.387125Z",
     "iopub.status.idle": "2022-10-02T15:18:48.396611Z",
     "shell.execute_reply": "2022-10-02T15:18:48.395535Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.387750Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_latency(network, dummy_data):\n",
    "\n",
    "    iterations = 1000\n",
    "\n",
    "    cudnn.enabled = True\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for _ in range(100):\n",
    "            network(dummy_data)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        t_start = time.time()\n",
    "\n",
    "        for _ in range(iterations):\n",
    "            network(dummy_data)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        elapsed_time = time.time() - t_start\n",
    "        latency = elapsed_time / iterations\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return latency * 1000 # in ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61afbd0",
   "metadata": {},
   "source": [
    "## Weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df988011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(n_exits,ordering):\n",
    "    \n",
    "    if ordering == \"UNIF\":\n",
    "        n=1/n_exits\n",
    "        branches_weights = [round(n,4) for _ in range(0,n_exits)]\n",
    "        ensemble_weights = branches_weights.copy()\n",
    "\n",
    "    else:\n",
    "        m = sum(range(1,n_exits+1))\n",
    "        n=1/m\n",
    "        \n",
    "        branches_weights=[round(n*i,4) for i in range(1,n_exits+1)]\n",
    "        ensemble_weights = branches_weights.copy()\n",
    "\n",
    "        if ordering == \"MIX\" or ordering==\"DESC\":\n",
    "            branches_weights=sorted(branches_weights,reverse=True)\n",
    "            if ordering==\"DESC\":\n",
    "                ensemble_weights=sorted(ensemble_weights,reverse=True)\n",
    "\n",
    "    return branches_weights, ensemble_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc2de5",
   "metadata": {},
   "source": [
    "## RUN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8703b8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.400025Z",
     "iopub.status.busy": "2022-10-02T15:18:48.399771Z",
     "iopub.status.idle": "2022-10-02T15:18:48.422803Z",
     "shell.execute_reply": "2022-10-02T15:18:48.421882Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.400001Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(epochs, batch_size, learning_rate, network_name, se_or_me, weight_ordering, dataset, ft_or_tr, img_size, dataset_save_path, output_path):\n",
    "    \n",
    "    ordering = weight_ordering.lower() if se_or_me == \"ME\" else \"\"\n",
    "    notebook_name = \"{}-{}{}-{}-{}-{}\".format(network_name, se_or_me, ordering, dataset, ft_or_tr, img_size)\n",
    "    print(\"Notebook name: \" + notebook_name)\n",
    "    output_path = os.path.join(output_path, notebook_name)\n",
    "    #------------------------------------------------\n",
    "    os.makedirs(output_path,exist_ok=True)\n",
    "    os.makedirs(dataset_save_path,exist_ok=True)\n",
    "    log_file = os.path.join(output_path,\"log.txt\")\n",
    "    #------------------------------------------------\n",
    "    #set seeds\n",
    "    seed=420\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    #------------------------------------------------\n",
    "    train_loader, validation_loader, test_loader, n_classes, img_channels, classes_weights = get_dataloaders(dataset, dataset_save_path, img_size, batch_size)\n",
    "    #------------------------------------------------\n",
    "    #set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #------------------------------------------------\n",
    "    is_single_exit = True if se_or_me == \"SE\" else False\n",
    "    pretrained = True if ft_or_tr == \"FT\" else False\n",
    "    #------------------------------------------------\n",
    "    network, n_exits = get_network(network_name, is_single_exit, pretrained, n_classes, img_channels)\n",
    "    network.to(device)\n",
    "    #------------------------------------------------\n",
    "    branches_weights, ensemble_weights = get_weights(n_exits,weight_ordering)\n",
    "    print(\"N exits: \", n_exits)\n",
    "    print(\"weights ordering: \",weight_ordering)\n",
    "    print(\"branches weights: \", branches_weights)\n",
    "    print(\"ensemble weights: \", ensemble_weights)\n",
    "    #------------------------------------------------\n",
    "    if classes_weights is not None:\n",
    "        train_criterion = nn.CrossEntropyLoss(weight=classes_weights.to(device))\n",
    "    else:\n",
    "        train_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    test_criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(network.parameters(), learning_rate)\n",
    "    #------------------------------------------------\n",
    "    #print(network)\n",
    "    #------------------------------------------------\n",
    "    with open(log_file,\"w\") as log:\n",
    "        log.write(notebook_name+\"\\n\\n\\n\")\n",
    "\n",
    "    training_start = time.time()\n",
    "\n",
    "    if is_single_exit:\n",
    "        #train\n",
    "        history, best_model_pth= train_se(network, device, train_criterion, test_criterion, optimizer, epochs, train_loader, validation_loader, output_path, log_file)\n",
    "        #plots\n",
    "        epochs_trained = len(history[\"train_loss\"])\n",
    "        show_plot(epochs_trained, np.array(history[\"train_loss\"]), np.array(history[\"valid_loss\"]), output_path, \"loss\", \"SE_losses\")\n",
    "        show_plot(epochs_trained, np.array(history[\"train_top1\"]), np.array(history[\"valid_top1\"]), output_path, \"acc\", \"SE_accuracies\")\n",
    "\n",
    "    else:\n",
    "        #train\n",
    "        history, best_model_pth = train_ee(network, device, train_criterion, test_criterion, optimizer, epochs, train_loader, validation_loader, output_path, log_file, branches_weights, ensemble_weights)\n",
    "        #plots\n",
    "        epochs_trained = len(history[\"train_net_loss\"])\n",
    "        show_plot(epochs_trained, np.array(history[\"train_net_loss\"]), np.array(history[\"valid_net_loss\"]), output_path, \"loss\", \"EE_net_losses\")\n",
    "        show_plot(epochs_trained, np.array(history[\"train_net_top1\"]), np.array(history[\"valid_net_top1\"]), output_path, \"acc\", \"EE_net_accuracies\")\n",
    "        for i in range(len(branches_weights)):\n",
    "            show_plot(epochs_trained, np.array(history[\"train_branches_losses\"])[:,i], np.array(history[\"valid_branches_losses\"])[:,i], output_path, \"loss\", \"EE_br\"+str(i+1)+\"_losses\")\n",
    "            show_plot(epochs_trained, np.array(history[\"train_branches_top1\"])[:,i], np.array(history[\"valid_branches_top1\"])[:,i], output_path, \"acc\", \"EE_br\"+str(i+1)+\"_acc\")\n",
    "\n",
    "    training_duration = time.time()-training_start\n",
    "    tds = f\"training took {training_duration/3600:.2f}h or {training_duration/60:.2f}mins or {training_duration:.1f}s\"\n",
    "    #------------------------------------------------\n",
    "    network = torch.load(best_model_pth)\n",
    "    network.to(device)\n",
    "\n",
    "    if is_single_exit:\n",
    "        test_loss, (test_top1, test_top5), test_time = validate_se(network, device, test_criterion, test_loader)\n",
    "        log_output_se(\"testing\", 1, 1, test_loss, test_top1, test_top5, test_time, log_file)\n",
    "    else:\n",
    "        test_net_loss, test_branches_losses, (test_net_top1,test_net_top5), (test_branches_top1, test_branches_top5), test_time = validate_ee(network, device, test_criterion, test_loader, branches_weights, ensemble_weights)\n",
    "        log_output_ee(\"testing\", 1, 1, test_net_loss, test_branches_losses, test_net_top1, test_net_top5, test_branches_top1, test_branches_top5, test_time, log_file)\n",
    "    #------------------------------------------------\n",
    "    input_size = (1, img_channels, img_size, img_size)\n",
    "    dummy_data = torch.rand(*input_size).to(device)\n",
    "\n",
    "    Mparams = compute_params(network)\n",
    "    Mmacs = compute_macs(network, dummy_data)\n",
    "    latency_ms = compute_latency(network, dummy_data)\n",
    "\n",
    "    net_eval_str = \"\\n\\n\"+tds+\"\\n\"\n",
    "    net_eval_str += f\"#Parameters: {Mparams:.3f}M\\n\"\n",
    "    net_eval_str += f\"#Macs: {Mmacs:.3f}M\\n\"\n",
    "    net_eval_str += f\"Latency: {latency_ms:.3f} ms\"\n",
    "\n",
    "    print(net_eval_str)\n",
    "    with open(log_file,\"a\") as log:\n",
    "        log.write(\"\\n\"+net_eval_str)\n",
    "\n",
    "\n",
    "    #------------------------------------------------\n",
    "    #------------------------------------------------\n",
    "    #------------------------------------------------\n",
    "    #   ENSEMBLE SELECTION \n",
    "    #------------------------------------------------\n",
    "    #------------------------------------------------\n",
    "    #------------------------------------------------\n",
    "\n",
    "    ens_log_file = os.path.join(output_path,\"log_ensemble.txt\")\n",
    "    with open(log_file,\"w\") as ens_log:\n",
    "        ens_log.write(notebook_name+\" ensembles\"+\"\\n\\n\\n\")\n",
    "    \n",
    "    best_model = network\n",
    "\n",
    "    ensembles_results = validate_all_ensembles(best_model, device, validation_loader, ensemble_weights)\n",
    "    best_ens_key = max(ensembles_results, key=lambda key: ensembles_results[key])\n",
    "\n",
    "    with open(ens_log_file,\"a\") as ens_log:\n",
    "        ens_log.write(\"ENSEMBLES on VALIDATION:\\n\")\n",
    "        for k,v in ensembles_results.items():\n",
    "            ens_log.write(f\"{k}: [{v[0]:.3f}, {v[1]:.3f}]\\n\")\n",
    "        ens_log.write(\"\\n\\n\")\n",
    "\n",
    "    best_ens_active_exits = []\n",
    "    best_ens_active_weights = []\n",
    "    for n,(bit, ens_weight) in enumerate(zip(best_ens_key, ensemble_weights),1):\n",
    "        if bit==\"1\":\n",
    "            best_ens_active_exits.append(n)\n",
    "            best_ens_active_weights.append(ens_weight)\n",
    "\n",
    "    log_best_ens_active_exits = \"[\"+ \",\".join(map(str,best_ens_active_exits))+\"]\"\n",
    "    log_best_ens_active_weights = \"[\"+ \",\".join(map(str,best_ens_active_weights))+\"]\"\n",
    "    \n",
    "    with open(ens_log_file,\"a\") as ens_log:\n",
    "        ens_log.write(f\"BEST:    key: {best_ens_key}, Top1: {ensembles_results[best_ens_key][0]:.3f}, Top5: {ensembles_results[best_ens_key][1]:.3f}\\n\")\n",
    "        ens_log.write(f\"Active exits: \"+log_best_ens_active_exits+\"\\n\")\n",
    "        ens_log.write(f\"Ensemble weights: \"+log_best_ens_active_weights+\"\\n\\n\\n\")\n",
    "\n",
    "    best_ensemble_net = best_model.extract_subnetwork(best_ens_active_exits)\n",
    "    torch.save(best_ensemble_net,os.path.join(output_path,\"best_subnet.pth\"))\n",
    "\n",
    "    if isinstance(best_ensemble_net,MySENetwork):\n",
    "        (test_top1, test_top5), test_time = test_subnet_se(best_ensemble_net, device, test_loader)\n",
    "    else:\n",
    "        (test_top1, test_top5), test_time = test_subnet_ee(best_ensemble_net, device, test_loader, best_ens_active_weights)\n",
    "    \n",
    "    with open(ens_log_file,\"a\") as ens_log:\n",
    "        ens_log.write(f\"TEST: top1:{test_top1:.3f}, top5:{test_top5:.3f}, time:{test_time:.1f}s\")\n",
    "\n",
    "    input_size = (1, img_channels, img_size, img_size)\n",
    "    dummy_data = torch.rand(*input_size).to(device)\n",
    "\n",
    "    Mparams = compute_params(best_ensemble_net)\n",
    "    Mmacs = compute_macs(best_ensemble_net, dummy_data)\n",
    "    latency_ms = compute_latency(best_ensemble_net, dummy_data)\n",
    "\n",
    "    net_eval_str = f\"#Parameters: {Mparams:.3f}M\\n\"\n",
    "    net_eval_str += f\"#Macs: {Mmacs:.3f}M\\n\"\n",
    "    net_eval_str += f\"Latency: {latency_ms:.3f} ms\"\n",
    "\n",
    "    with open(ens_log_file,\"a\") as ens_log:\n",
    "        ens_log.write(\"\\n\\n\"+net_eval_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a251dbc",
   "metadata": {},
   "source": [
    "# START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0ff00bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.425957Z",
     "iopub.status.busy": "2022-10-02T15:18:48.424984Z",
     "iopub.status.idle": "2022-10-02T15:18:48.435656Z",
     "shell.execute_reply": "2022-10-02T15:18:48.435070Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.425920Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs=100\n",
    "batch_size=64\n",
    "learning_rate=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224d5f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-02T15:18:48.450099Z",
     "iopub.status.busy": "2022-10-02T15:18:48.448972Z",
     "iopub.status.idle": "2022-10-02T15:23:10.316900Z",
     "shell.execute_reply": "2022-10-02T15:23:10.315534Z",
     "shell.execute_reply.started": "2022-10-02T15:18:48.449850Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_save_path = \"./datasets\"\n",
    "output_path = \"./outputs\"\n",
    "weights_path = \"./weights\"\n",
    "\n",
    "torch.hub.set_dir(weights_path)\n",
    "\n",
    "network_names = [\"resnet50\",\"vgg16\",\"vgg16full\",\"densenet169\",\"mobilenetv3small\",\"mobilenetv3smallfull\",\"efficientnetB5\",\"efficientnetB5full\"]\n",
    "ses_or_mes = [\"SE\",\"ME\"]\n",
    "weights_orderings = [\"DESC\",\"ASC\", \"MIX\",\"UNIF\"]\n",
    "datasets = [\"cifar10\",\"cifar100\",\"eurosatW\",\"fashionMNIST\",\"gtsrbW\",\"tiny_imagenet\"]\n",
    "fts_or_trs = [\"TR\",\"FT\"]\n",
    "img_sizes = [64,224]\n",
    "\n",
    "for ft_or_tr in fts_or_trs:\n",
    "    for img_size in img_sizes:\n",
    "        for network_name in network_names:\n",
    "            for se_or_me in ses_or_mes:\n",
    "                for weight_ordering in weights_orderings:\n",
    "                    for dataset in datasets:\n",
    "                    \n",
    "                        if se_or_me == \"SE\" and (weight_ordering!=\"DESC\" or \"full\" in network_names):\n",
    "                            pass\n",
    "                        else:\n",
    "                            run(epochs, batch_size, learning_rate, network_name, se_or_me, weight_ordering, dataset, ft_or_tr, img_size, dataset_save_path, output_path)\n",
    "                            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15404.448864,
   "end_time": "2022-06-28T19:24:56.641609",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-28T15:08:12.192745",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "d12e26f72a40d5c48233c54861fca038d6a92135fc0e5e920944e69c69b6b29d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
